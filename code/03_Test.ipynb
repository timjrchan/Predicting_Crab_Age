{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helpers\n",
    "import cuml, cudf, cupy\n",
    "import warnings\n",
    "\n",
    "# import preprocessing libraries and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# import models\n",
    "import xgboost as xgb # XGBoost\n",
    "from cuml.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from cuml.ensemble import RandomForestRegressor # Random Forest\n",
    "\n",
    "# surpress future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# set dataframe display \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sex  length  diameter  height     weight  shucked_weight  viscera_weight  shell_weight\n",
      "0   I  1.0500    0.7625  0.2750   8.618248        3.657085        1.729319      2.721552\n",
      "1   I  1.1625    0.8875  0.2750  15.507176        7.030676        3.246018      3.968930\n",
      "2   F  1.2875    0.9875  0.3250  14.571643        5.556502        3.883882      4.819415\n",
      "3   F  1.5500    0.9875  0.3875  28.377849       13.380964        6.548735      7.030676\n",
      "4   I  1.1125    0.8500  0.2625  11.765042        5.528153        2.466407      3.331066\n"
     ]
    }
   ],
   "source": [
    "# import test data\n",
    "\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "test_ids = test_df['id']\n",
    "\n",
    "test_df = helpers.clean_headers(test_df)\n",
    "\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num__length  num__diameter  num__height  num__weight  num__shucked_weight  num__viscera_weight  num__shell_weight  cat__sex_F  cat__sex_I  cat__sex_M\n",
      "0    -0.940227      -1.115249    -0.798762    -1.174409            -1.153502            -1.197655          -1.125492         0.0         1.0         0.0\n",
      "1    -0.548169      -0.586910    -0.798762    -0.629467            -0.552334            -0.654334          -0.776635         0.0         1.0         0.0\n",
      "2    -0.112548      -0.164238    -0.256807    -0.703471            -0.815029            -0.425835          -0.538778         1.0         0.0         0.0\n",
      "3     0.802256      -0.164238     0.420637     0.388656             0.579278             0.528784           0.079651         1.0         0.0         0.0\n",
      "4    -0.722417      -0.745411    -0.934251    -0.925485            -0.820081            -0.933611          -0.955027         0.0         1.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# normalize numerical variables and one hot encode categorical variables\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['length', 'diameter', 'height', 'weight','shucked_weight', 'viscera_weight', 'shell_weight']),\n",
    "        ('cat', OneHotEncoder(), ['sex'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# apply transformations\n",
    "scaled_data = preprocessor.fit_transform(test_df)\n",
    "\n",
    "# get column headers\n",
    "column_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Convert transformed data back to Dataframe\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=column_names)\n",
    "\n",
    "\n",
    "print(scaled_df.head()) # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num__length  num__diameter  num__height  num__weight  num__shucked_weight  num__viscera_weight  num__shell_weight  cat__sex_F  cat__sex_I  cat__sex_M  shell_weight_ratio  shucked_weight_ratio  vis_shucked_weight_ratio  surface_area\n",
      "0    -0.940227      -1.115249    -0.798762    -1.174409            -1.153502            -1.197655          -1.125492         0.0         1.0         0.0            0.958347              0.982198                  1.038277      0.823559\n",
      "1    -0.548169      -0.586910    -0.798762    -0.629467            -0.552334            -0.654334          -0.776635         0.0         1.0         0.0            1.233798              0.877463                  1.184672      0.252683\n",
      "2    -0.112548      -0.164238    -0.256807    -0.703471            -0.815029            -0.425835          -0.538778         1.0         0.0         0.0            0.765884              1.158582                  0.522478      0.014518\n",
      "3     0.802256      -0.164238     0.420637     0.388656             0.579278             0.528784           0.079651         1.0         0.0         0.0            0.204939              1.490464                  0.912834     -0.103485\n",
      "4    -0.722417      -0.745411    -0.934251    -0.925485            -0.820081            -0.933611          -0.955027         0.0         1.0         0.0            1.031921              0.886110                  1.138438      0.422935\n"
     ]
    }
   ],
   "source": [
    "### Feature Engineering as train_df\n",
    "\n",
    "featured_df = scaled_df.copy()\n",
    "\n",
    "# ratio of shell weight to entire weight\n",
    "featured_df['shell_weight_ratio'] = featured_df['num__shell_weight'] / featured_df['num__weight']\n",
    "\n",
    "# meat yield\n",
    "featured_df['shucked_weight_ratio'] = featured_df['num__shucked_weight'] / featured_df['num__weight']\n",
    "\n",
    "# ratio of viscera weight to shucked weight\n",
    "featured_df['vis_shucked_weight_ratio'] = featured_df['num__viscera_weight'] / featured_df['num__shucked_weight']\n",
    "\n",
    "# General Surface Area\n",
    "featured_df['surface_area'] = np.pi * 0.5 * featured_df['num__length'] * 0.5 * featured_df['num__diameter'] \n",
    "\n",
    "\n",
    "print(featured_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num__length                 float32\n",
      "num__diameter               float32\n",
      "num__height                 float32\n",
      "num__weight                 float32\n",
      "num__shucked_weight         float32\n",
      "num__viscera_weight         float32\n",
      "num__shell_weight           float32\n",
      "cat__sex_F                  float32\n",
      "cat__sex_I                  float32\n",
      "cat__sex_M                  float32\n",
      "shell_weight_ratio          float32\n",
      "shucked_weight_ratio        float32\n",
      "vis_shucked_weight_ratio    float32\n",
      "surface_area                float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convert the values to float32 for GPU processing\n",
    "helpers.convert_float32(featured_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost\n",
    "bst = xgb.Booster()\n",
    "\n",
    "# Load model\n",
    "bst.load_model('best_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Pandas DF to CuPy array for GPU processing\n",
    "cupy_array = cupy.array(featured_df.values)\n",
    "\n",
    "# Create a cuDF DF from CuPy array\n",
    "cudf_df = cudf.DataFrame(cupy_array, columns = featured_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver to DMatrix so XGBoost can process\n",
    "dtest = xgb.DMatrix(data = featured_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values from model\n",
    "predictions = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  Age\n",
      "0  74051    8\n",
      "1  74052    8\n",
      "2  74053   10\n",
      "3  74054   10\n",
      "4  74055    7\n"
     ]
    }
   ],
   "source": [
    "# Convert predictions into df\n",
    "predictions_df = pd.DataFrame(predictions, columns = ['Age'])\n",
    "\n",
    "# Add the column id back\n",
    "predictions_df['id'] = test_ids.values\n",
    "\n",
    "# Reorder the dataframe\n",
    "predictions_df = predictions_df[['id', 'Age']]\n",
    "\n",
    "# round the prediction values and round the ages to integer\n",
    "predictions_df['Age'] = (np.round(predictions_df['Age'])).astype(int)\n",
    "\n",
    "print(predictions_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
